{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Reading the csv file\n",
    "events = pd.read_csv('events.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Taking a subset of the file for faster prototyping\n",
    "events = events.iloc[1:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>visitorid</th>\n",
       "      <th>event</th>\n",
       "      <th>itemid</th>\n",
       "      <th>transactionid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1433224214164</td>\n",
       "      <td>992329</td>\n",
       "      <td>view</td>\n",
       "      <td>248676</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1433221999827</td>\n",
       "      <td>111016</td>\n",
       "      <td>view</td>\n",
       "      <td>318965</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1433221955914</td>\n",
       "      <td>483717</td>\n",
       "      <td>view</td>\n",
       "      <td>253185</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1433221337106</td>\n",
       "      <td>951259</td>\n",
       "      <td>view</td>\n",
       "      <td>367447</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1433224086234</td>\n",
       "      <td>972639</td>\n",
       "      <td>view</td>\n",
       "      <td>22556</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp  visitorid event  itemid  transactionid\n",
       "1  1433224214164     992329  view  248676            NaN\n",
       "2  1433221999827     111016  view  318965            NaN\n",
       "3  1433221955914     483717  view  253185            NaN\n",
       "4  1433221337106     951259  view  367447            NaN\n",
       "5  1433224086234     972639  view   22556            NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convering timestamp into pandas datetime format\n",
    "events.timestamp = pd.to_datetime(events.timestamp, unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['view', 'addtocart', 'transaction'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking different unique events in the dataframe\n",
    "events.event.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creating dataframe for each event\n",
    "view = events.loc[events.event == 'view']\n",
    "addtocart = events.loc[events.event == 'addtocart']\n",
    "transaction = events.loc[events.event == 'transaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Keeping relevant columns\n",
    "view = view.loc[:,['visitorid','itemid']]\n",
    "addtocart = addtocart.loc[:,['visitorid', 'itemid']]\n",
    "transaction = transaction.loc[:,['visitorid', 'itemid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creating visitorid as index\n",
    "view.index = view.visitorid\n",
    "view.drop('visitorid', axis=1, inplace =True)\n",
    "addtocart.index = addtocart.visitorid\n",
    "addtocart.drop('visitorid', axis=1, inplace = True)\n",
    "transaction.index = transaction.visitorid\n",
    "transaction.drop('visitorid', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creating history matrix\n",
    "history_view = pd.get_dummies(view, columns=['itemid'])\n",
    "history_addtocart = pd.get_dummies(addtocart, columns=['itemid'])\n",
    "history_transaction = pd.get_dummies(transaction, columns=['itemid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Counting the duplicate rows and adding the count\n",
    "history_view = history_view.groupby([history_view.index])[history_view.filter(regex='itemid_.*').columns].sum()\n",
    "history_addtocart = history_addtocart.groupby([history_addtocart.index])[history_addtocart.filter(regex='itemid_.*').columns].sum()\n",
    "history_transaction = history_transaction.groupby([history_transaction.index])[history_transaction.filter(regex='itemid_.*').columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Converting into a union dataframe\n",
    "def union_dataframe(history_event, ind_union, col_union):\n",
    "    \n",
    "    history_event = history_event.copy()\n",
    "    index_event_df = pd.DataFrame(0, index=ind_union.difference(history_event.index), columns= history_event.columns)\n",
    "    history_event = pd.concat([history_event, index_event_df], axis=0)\n",
    "    col_event_df = pd.DataFrame(0,index=history_event.index, columns=col_union.difference(history_event.columns))\n",
    "    history_event= pd.concat([history_event, col_event_df], axis=1)\n",
    "    #Sort rows and columns for uniformity\n",
    "    history_event = history_event.reindex_axis(sorted(history_event.columns), axis=1).sort_index()\n",
    "    return history_event\n",
    "\n",
    "ind_union = history_view.index.union(history_addtocart.index).union(history_transaction.index)\n",
    "col_union = history_view.columns.union(history_addtocart.columns).union(history_transaction.columns)\n",
    "history_view =  union_dataframe(history_view,ind_union, col_union)\n",
    "history_addtocart =  union_dataframe(history_addtocart,ind_union, col_union)\n",
    "history_transaction =  union_dataframe(history_transaction,ind_union, col_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "visitorid\n",
       "137                                      [itemid_383819]\n",
       "202                                       [itemid_62641]\n",
       "458                                      [itemid_182419]\n",
       "533                                      [itemid_360664]\n",
       "581                                      [itemid_388097]\n",
       "765                                      [itemid_287017]\n",
       "845                                      [itemid_351530]\n",
       "1322                                      [itemid_96924]\n",
       "1485                                      [itemid_32971]\n",
       "1654                                     [itemid_123555]\n",
       "1713                                     [itemid_270144]\n",
       "1722                                     [itemid_381314]\n",
       "1756       [itemid_150100, itemid_296448, itemid_346892]\n",
       "2081                                     [itemid_221146]\n",
       "2160                                     [itemid_280029]\n",
       "2366                                     [itemid_221428]\n",
       "2610                                     [itemid_159856]\n",
       "2900                                     [itemid_280330]\n",
       "3023                                     [itemid_356571]\n",
       "3068                                      [itemid_35913]\n",
       "3109                                     [itemid_463280]\n",
       "3189                                     [itemid_359607]\n",
       "3215                                     [itemid_220165]\n",
       "3849                                      [itemid_99281]\n",
       "3877                                     [itemid_185553]\n",
       "4078                                     [itemid_272907]\n",
       "4550                                     [itemid_271548]\n",
       "4652                                     [itemid_167505]\n",
       "5129                       [itemid_67748, itemid_143362]\n",
       "5628                                     [itemid_197708]\n",
       "                               ...                      \n",
       "953999                                                []\n",
       "994582                                                []\n",
       "1000567                                               []\n",
       "1001673                                               []\n",
       "1018888                                               []\n",
       "1043433                                               []\n",
       "1061098                                               []\n",
       "1067960                                               []\n",
       "1092695                                               []\n",
       "1109107                                               []\n",
       "1111359                                               []\n",
       "1128242                                               []\n",
       "1162854                                               []\n",
       "1162858                                               []\n",
       "1204271                                               []\n",
       "1233931                                               []\n",
       "1253168                                               []\n",
       "1279042                                               []\n",
       "1282975                                               []\n",
       "1318394                                               []\n",
       "1326841                                               []\n",
       "1331125                                               []\n",
       "1339727                                               []\n",
       "1344887                                               []\n",
       "1345880                                               []\n",
       "1359207                                               []\n",
       "1380258                                               []\n",
       "1381164                                               []\n",
       "1402642                                               []\n",
       "1406087                                               []\n",
       "dtype: object"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check which visitor has viewed which item\n",
    "df = history_view.copy()\n",
    "cols = df.columns\n",
    "bt = df.apply(lambda x: x > 0)\n",
    "bt.apply(lambda x: list(cols[x.values]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Functions to calculate entropy\n",
    "#k11, k12, k21, and k22 are the counts of simultaneously occuring of two events\n",
    "\n",
    "def denormEntropy1(counts):\n",
    "    '''Computes the entropy of a list of counts scaled by the sum of the counts. If the inputs sum to one, this is just the normal definition of entropy'''\n",
    "    lg = np.log(np.divide(k,float(np.sum(k))))\n",
    "    lg[lg==-np.inf]=0\n",
    "    return -np.sum(k*lg)\n",
    "\n",
    "def llr_2x2(k11, k12, k21, k22):\n",
    "    '''Special case of llr with a 2x2 table'''\n",
    "    return 2 * (denormEntropy([k11+k12, k21+k22]) +\n",
    "                denormEntropy([k11+k21, k12+k22]) -\n",
    "                denormEntropy([k11, k12, k21, k22]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculating counts k11, k12, k21, k22 for each item, item combination in history matrix\n",
    "#Then calculating cross-cooccurence matrix\n",
    "\n",
    "def calc_counts_row(item1, item2):\n",
    "    new_item = np.concatenate((item1.reshape(-1,1),item2.reshape(-1,1)), axis=1)\n",
    "    if((np.any(new_item[:,1]<0)==True)|(np.any(new_item[:,0]<0)==True)):\n",
    "        raise ValueError('History matrix has negative element')\n",
    "    k22 = len(new_item[(new_item[:,0]==0)&(new_item[:,1]==0)])\n",
    "    k21 = len(new_item[(new_item[:,0]==0)&(new_item[:,1]!=0)])\n",
    "    k12 = len(new_item[(new_item[:,0]!=0)&(new_item[:,1]==0)])\n",
    "    k11 = len(new_item[(new_item[:,0]!=0)&(new_item[:,1]!=0)])\n",
    "    \n",
    "    return k11,k12,k21,k22\n",
    "\n",
    "def calc_cooccurence_matrix(history_event):\n",
    "    coo_matrix = np.zeros((history_event.shape[1],history_event.shape[1]))\n",
    "    for item1_index in range(history_event.shape[1]):\n",
    "        for item2_index in range(history_event.shape[1]):\n",
    "            item1 = history_event[:,item1_index]\n",
    "            item2 = history_event[:,item2_index]\n",
    "            llr = llr_2x2(calc_counts_row(item1,item2))\n",
    "            coo_matrix[item1_index,item2_index] = llr\n",
    "    return coo_matrix\n",
    "\n",
    "def calc_cross_coocurence_matrix(primary_history, secondary_event):\n",
    "    coo_matrix = np.zeros((primary_history.shape[1], primary_history.shape[1]))\n",
    "    for item1_index in range(primary_history.shape[1]):\n",
    "        for item2_index in range(secondary_event.shape[1]):\n",
    "            item1 = primary_history[:,item1_index]\n",
    "            item2 = secondary_event[:,item2_index]\n",
    "            llr = llr_2x2(calc_counts_row(item1,item2))\n",
    "            coo_matrix[item1_index,item2_index] =llr\n",
    "    return coo_matrix\n",
    "\n",
    "def return_recommended_llr(coo_matrix, user_history):\n",
    "    user_history = user_history.reshape(-1,1)\n",
    "    user_llr = np.dot(coo_matrix, user_history)\n",
    "    return llr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Recommendation training flow\n",
    "1. Creating a history matrix (including adding count for duplicate events by same user)\n",
    "2. Converting it into union history matrix\n",
    "3. Calculating cooccurence and cross-cooccurence matrix\n",
    "4. Calculating user_llr for each event\n",
    "5. Adding user_llr and recommending based on the number of recommendations specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'eventNames': ['view','addtocart', 'transaction'],\n",
    "          'primaryEvent' : 2,\n",
    "          'algorithm' : {'name': ['URz'],\n",
    "                         'no_recommendations': 3,\n",
    "                         'time_dependent': False}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siddharth/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:184: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "u = urecommend(params)\n",
    "u.fit(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['itemid_102061', 'itemid_328025', 'itemid_417464']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_history = {}\n",
    "user_history['view']=[['itemid_128499', 1],['itemid_22556', 3]]\n",
    "user_history['transaction']=[['itemid_21989', 1]]\n",
    "user_history['addtocart'] = None\n",
    "u.predict(user_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class urecommend:\n",
    "    \n",
    "    def __init__(self, params):\n",
    "        self.eventNames = params['eventNames']\n",
    "        self.primaryEvent = params['primaryEvent']\n",
    "        self.no_recommendations = params['algorithm']['no_recommendations']\n",
    "        imp.reload(logging)\n",
    "        logging.basicConfig(filename= 'urecommend_log.log',format='%(asctime)s %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p',level=logging.DEBUG)\n",
    "        \n",
    "        if not isinstance(self.eventNames, list):\n",
    "            raise TypeError('eventNames should be of type list')\n",
    "        if not isinstance(self.primaryEvent, int):\n",
    "            raise TypeError('primaryEvent should be of type int')\n",
    "        if not isinstance(self.no_recommendations, int):\n",
    "            raise TypeError('no_recommendations should be of type int')\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \n",
    "        self.X = X\n",
    "        #Check if input dataframe has all required columns or not\n",
    "        if isinstance(self.X, pd.DataFrame):\n",
    "            if(not set(['visitorid','event','itemid']).issubset(set(self.X.columns.values))):\n",
    "                raise ValueError('Incomplete input dataframe')\n",
    "        else:\n",
    "            raise TypeError('Input is not a dataframe')\n",
    "        \n",
    "        #Check if params events are not equal to input dataframe unique events\n",
    "        if(set(self.X.event.unique())!=set(self.eventNames)):\n",
    "            if(len(self.X.event.unique())>len(self.eventNames)):\n",
    "                raise ValueError('Input dataframes have more unique events than specified in input params')\n",
    "            elif(len(self.X.event.unique())<len(self.eventNames)):\n",
    "                diff_elem = set(self.eventNames) - set(self.X.event.unique())\n",
    "                logging.info('Input dataframe have no datapoints for '+ ' and '.join(diff_elem))\n",
    "        \n",
    "        #Create history matrix\n",
    "        self.create_history_matrix()\n",
    "        logging.info('History matrices created')\n",
    "        \n",
    "        #Create union history matrix\n",
    "        self.create_union_history_matrix()\n",
    "        logging.info('Union of history matrices created')\n",
    "        \n",
    "        #Calculating coocurrence and cross-coocurrence matrices\n",
    "        self.create_coocurrence_matrix()\n",
    "        logging.info('Coocurrence matrices created')\n",
    "        logging.info('u-recommender trained to the data')\n",
    "        \n",
    "    def predict(self, user_history):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function predicts the recommended products\n",
    "        \n",
    "        user_history (dictionary of length equal to number of events in X)\n",
    "                    :keys will be event name\n",
    "                     and values will be a 2D list of item_id and count pairs\n",
    "                     if they are no items for any event put value for that event will be none\n",
    "        \"\"\"\n",
    "        #Check if user_history has more or less items than total item\n",
    "        if(set(self.X.event.unique())==set(user_history.keys())):\n",
    "            raise ValueError('All elements are not present in user_history')\n",
    "        \n",
    "        user_llr = np.zeros((len(self.coocurrence[list(self.coocurrence.keys())[0]]),1))\n",
    "        \n",
    "        for event,matrix in user_history.items():\n",
    "                        \n",
    "            user = pd.DataFrame(0,index = self.coocurrence[list(self.coocurrence.keys())[0]].index, columns =['user'])\n",
    "            if(matrix is not None):\n",
    "                \n",
    "                #Check if input user_history is list of list\n",
    "                if(not isinstance(matrix, list)):\n",
    "                    raise ValueError('Values of user_history '+event+' key should be list of list')\n",
    "                \n",
    "                matrix = dict(matrix)\n",
    "\n",
    "                for index,series in user.iterrows():\n",
    "                    if(index in list(matrix.keys())):\n",
    "                        user.loc[index,'user']=matrix[index]\n",
    "        \n",
    "            user_llr += self.return_recommended_llr(self.coocurrence[event], user)\n",
    "        \n",
    "        user_llr = pd.DataFrame(user_llr, index=self.coocurrence[list(self.coocurrence.keys())[0]].index, columns =['llr'])\n",
    "        return list(user_llr.sort_values('llr', axis=0, ascending=False).index)[:self.no_recommendations]\n",
    "        \n",
    "    def create_history_matrix(self):\n",
    "        \n",
    "        #Initializing empty dictionary\n",
    "        self.history = {}\n",
    "        \n",
    "        for eventName in self.eventNames:\n",
    "            \n",
    "            #Taking out only event specific columns\n",
    "            self.history[eventName] = self.X.loc[self.X.event == eventName]\n",
    "            #Taking out required columns\n",
    "            self.history[eventName] = self.history[eventName].loc[:,['visitorid','itemid']]\n",
    "            #Making visitorid as index\n",
    "            self.history[eventName].index = self.history[eventName].visitorid\n",
    "            self.history[eventName].drop('visitorid', axis=1, inplace =True)\n",
    "            #creating dummy variable for each itemid\n",
    "            self.history[eventName] = pd.get_dummies(self.history[eventName], columns=['itemid'])\n",
    "            #adding count when user participated in an event with same item more than once\n",
    "            self.history[eventName] = self.history[eventName].groupby([self.history[eventName].index])[self.history[eventName].filter(regex='itemid_.*').columns].sum()\n",
    "        \n",
    "        \n",
    "    def create_union_history_matrix(self):\n",
    "        \n",
    "        #Calculating index and column union\n",
    "        index_union = self.history[self.eventNames[0]].index\n",
    "        column_union = self.history[self.eventNames[0]].columns\n",
    "        \n",
    "        for eventName in self.eventNames[1:]:\n",
    "            index_union = index_union.union(self.history[eventName].index)\n",
    "            column_union = column_union.union(self.history[eventName].columns)\n",
    "        \n",
    "        #Creating union history event dataframe using index and column union\n",
    "        for eventName in self.eventNames:\n",
    "            self.history[eventName] = self.union_dataframe(self.history[eventName], index_union, column_union)\n",
    "    \n",
    "    def create_coocurrence_matrix(self):\n",
    "        \n",
    "        self.coocurrence = {}\n",
    "        \n",
    "        self.coocurrence[self.eventNames[self.primaryEvent]] = self.calc_cooccurence_matrix(self.history[self.eventNames[self.primaryEvent]])\n",
    "        logging.debug('cooccurence matrix of primary event - %s is calculated',self.eventNames[self.primaryEvent])\n",
    "        \n",
    "        for eventName in self.eventNames:\n",
    "            if(eventName!= self.eventNames[self.primaryEvent]):\n",
    "                self.coocurrence[eventName] = self.calc_cross_coocurence_matrix(self.history[self.eventNames[self.primaryEvent]], self.history[eventName])\n",
    "                logging.debug('cross-cooccurence matrix of event - %s is calculated',eventName)\n",
    "                \n",
    "    def union_dataframe(self, history_event, ind_union, col_union):\n",
    "    \n",
    "        history_event = history_event.copy()\n",
    "        index_event_df = pd.DataFrame(0, index=ind_union.difference(history_event.index), columns= history_event.columns)\n",
    "        history_event = pd.concat([history_event, index_event_df], axis=0)\n",
    "        col_event_df = pd.DataFrame(0,index=history_event.index, columns=col_union.difference(history_event.columns))\n",
    "        history_event= pd.concat([history_event, col_event_df], axis=1)\n",
    "        #Sort rows and columns for uniformity\n",
    "        history_event = history_event.reindex_axis(sorted(history_event.columns), axis=1).sort_index()\n",
    "        return history_event\n",
    "    \n",
    "    def calc_cooccurence_matrix(self, history_event):\n",
    "        \n",
    "        coo_matrix = pd.DataFrame(0, index = history_event.columns, columns = history_event.columns)\n",
    "        for item1_index in range(len(history_event.columns)):\n",
    "            for item2_index in range(len(history_event.columns)):\n",
    "                item1 = np.array(history_event.iloc[:,item1_index].values)\n",
    "                item2 = np.array(history_event.iloc[:,item2_index].values)\n",
    "                k11,k12,k21,k22 = self.calc_counts_row(item1,item2)\n",
    "                llr = self.llr_2x2(k11,k12,k21,k22)\n",
    "                coo_matrix.iloc[item1_index,item2_index] = llr\n",
    "        return coo_matrix\n",
    "    \n",
    "    def calc_cross_coocurence_matrix(self, primary_history, secondary_event):\n",
    "        coo_matrix = pd.DataFrame(0, index = primary_history.columns, columns = secondary_event.columns)\n",
    "        for item1_index in range(len(primary_history.columns)):\n",
    "            for item2_index in range(len(secondary_event.columns)):\n",
    "                item1 = np.array(primary_history.iloc[:,item1_index].values)\n",
    "                item2 = np.array(secondary_event.iloc[:,item2_index].values)\n",
    "                k11,k12,k21,k22 = self.calc_counts_row(item1,item2)\n",
    "                llr = self.llr_2x2(k11,k12,k21,k22)\n",
    "                coo_matrix.iloc[item1_index,item2_index] =llr\n",
    "        return coo_matrix\n",
    "    \n",
    "    def calc_counts_row(self, item1, item2):\n",
    "        new_item = np.concatenate((item1.reshape(-1,1),item2.reshape(-1,1)), axis=1)\n",
    "        if((np.any(new_item[:,1]<0)==True)|(np.any(new_item[:,0]<0)==True)):\n",
    "            raise ValueError('History matrix has negative element')\n",
    "        k22 = len(new_item[(new_item[:,0]==0)&(new_item[:,1]==0)])\n",
    "        k21 = len(new_item[(new_item[:,0]==0)&(new_item[:,1]!=0)])\n",
    "        k12 = len(new_item[(new_item[:,0]!=0)&(new_item[:,1]==0)])\n",
    "        k11 = len(new_item[(new_item[:,0]!=0)&(new_item[:,1]!=0)])\n",
    "\n",
    "        return k11,k12,k21,k22\n",
    "    \n",
    "    def llr_2x2(self, k11, k12, k21, k22):\n",
    "        '''Special case of llr with a 2x2 table'''\n",
    "        return 2 * (self.denormEntropy([k11+k12, k21+k22]) +\n",
    "                    self.denormEntropy([k11+k21, k12+k22]) -\n",
    "                    self.denormEntropy([k11, k12, k21, k22]))\n",
    "    \n",
    "    def denormEntropy(self,counts):\n",
    "        '''Computes the entropy of a list of counts scaled by the sum of the counts. \n",
    "            If the inputs sum to one, this is just the normal definition of entropy'''\n",
    "        lg = np.log(np.divide(counts,float(np.sum(counts))))\n",
    "        lg[lg==-np.inf]=0\n",
    "        return -np.sum(counts*lg)\n",
    "    \n",
    "    def return_recommended_llr(self, coo_dataframe, user_history):\n",
    "        \n",
    "        coo_matrix = coo_dataframe.as_matrix()\n",
    "        user = np.array(user_history.values).reshape(-1,1)\n",
    "        user_llr = np.dot(coo_matrix, user)\n",
    "        return user_llr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a={'a':1,'b':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s and d\n"
     ]
    }
   ],
   "source": [
    "a=['s','d']\n",
    "print(' and '.join(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix = [['a',1],['b',2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': '1', 'b': '2'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(np.array(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['a', '1'],\n",
       "       ['b', '2']], \n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict_keys' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-5ae461251ae3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'dict_keys' object does not support indexing"
     ]
    }
   ],
   "source": [
    "a.keys()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[list(a.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['eventNames', 'primaryEvent', 'algorithm'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(self, params.keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = pd.DataFrame(0, index=['0','100','200'], columns=['4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['1' '2'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-3d7ad0732ca9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/siddharth/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/siddharth/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_setitem_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/siddharth/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_tuple\u001b[0;34m(self, key, is_setter)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_setter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m                 \u001b[0mkeyidx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyidx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/siddharth/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1228\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1230\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s not in index'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['1' '2'] not in index\""
     ]
    }
   ],
   "source": [
    "b.loc[['1','2'],:] = [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.as_matrix()[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'v']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215529"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '21:55:29'\n",
    "int(str(pd.to_datetime(s).hour)+str(pd.to_datetime(s).minute)+str(pd.to_datetime(s).second))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b.loc['0','4']=49\n",
    "b.loc['100','4']=120\n",
    "b.loc['200','4']=11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       4\n",
       "0     49\n",
       "100  120\n",
       "200   11"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['100', '0', '200']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(b.sort_values('4',axis=0,ascending=False).index)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for integer, (index, series) in enumerate(b.iterrows()):\n",
    "    print(series['4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
